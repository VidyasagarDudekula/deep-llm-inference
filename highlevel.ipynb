{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae966c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import device\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da1452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stable_log_softmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, dim: int=-1):\n",
    "        max_values = torch.max(x, dim=dim, keepdim=True).values\n",
    "        shifted_x = x - max_values\n",
    "        log_probs = shifted_x - torch.logsumexp(shifted_x, dim=dim, keepdim=True)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "667d95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.manual_seed(42)\n",
    "x = torch.randn((1, 1, 50), requires_grad=True, generator=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b96a171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.nn.init.xavier_uniform_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19145c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2032, -0.1452, -0.1461, -0.1461,  0.2203,  0.0816,  0.2357,\n",
       "          -0.2022, -0.2430, -0.1916, -0.1648,  0.0992,  0.0877,  0.2035,\n",
       "          -0.1265, -0.1670,  0.1300, -0.0990,  0.1487, -0.0581,  0.1401,\n",
       "          -0.1903, -0.1236,  0.0747,  0.0518, -0.0625,  0.1460,  0.1665,\n",
       "          -0.1776, -0.1308,  0.2243, -0.0827, -0.0868, -0.2370, -0.1403,\n",
       "           0.0612, -0.0323, -0.1778,  0.0057, -0.1673, -0.2078, -0.1349,\n",
       "          -0.2144, -0.1560,  0.2449,  0.0463,  0.0755, -0.2285, -0.1609,\n",
       "          -0.0815]]], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c526f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = stable_log_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e733cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 10\n",
    "total_log_prob = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef743afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2448531687259674"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x, dim=-1).values.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "937d1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "seq_len = 10\n",
    "vocab_size = 50\n",
    "gen = torch.manual_seed(42)\n",
    "logits = torch.randn((batch_size, seq_len, vocab_size), generator=gen)\n",
    "target_ids = torch.randint(0, vocab_size, (batch_size, seq_len), generator=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adb72f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -1.6047,\n",
       "         -0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624,\n",
       "          1.6423, -0.1596, -0.4974,  0.4396, -0.7581,  1.0783,  0.8008,  1.6806,\n",
       "          1.2791,  1.2964,  0.6105,  1.3347, -0.2316,  0.0418, -0.2516,  0.8599,\n",
       "         -1.3847, -0.8712, -0.2234,  1.7174,  0.3189, -0.4245,  0.3057, -0.7746,\n",
       "         -1.5576,  0.9956, -0.8798, -0.6011, -1.2742,  2.1228, -1.2347, -0.4879,\n",
       "         -0.9138, -0.6581]),\n",
       " tensor([37, 39, 29,  7, 35, 38, 17, 14,  7, 24]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0, 0, :], target_ids[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f1b84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.gather(logits, dim=-1, index=target_ids.unsqueeze(-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9af38d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f2af8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4245, -0.4816,  1.0119, -0.4175, -1.0811,  0.9733, -0.0553, -1.7735,\n",
       "         -0.0388,  0.4151]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "805a1f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4816)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0, 1, target_ids[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb82d221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8721])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbeee4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maths.sequence_score import sequence_logprob, compute_nll\n",
    "from maths.softmax import stable_log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5897df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sftmax = stable_log_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a88443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1 = torch.manual_seed(42)\n",
    "gen2 = torch.manual_seed(43)\n",
    "logits_a = torch.randn((10, 2, 50), generator=gen1)\n",
    "target_ids_a = torch.randint(0, 50, (10, 2), generator=gen1)\n",
    "logits_b = torch.randn((10, 10, 50), generator=gen2)\n",
    "target_ids_b = torch.randint(0, 50, (10, 10), generator=gen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "185a5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_probs_a = sequence_logprob(logits_a, target_ids_a)\n",
    "seq_probs_b = sequence_logprob(logits_b, target_ids_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97914285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -9.5571,  -6.9069, -12.4230,  -8.7082, -11.6055, -10.6919,  -9.3203,\n",
       "        -10.5201,  -8.8899,  -6.3690])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_probs_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5422563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-46.3163, -44.3665, -44.4756, -40.5072, -49.0028, -42.1155, -37.8311,\n",
       "        -42.5875, -46.1512, -46.3185])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_probs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d226a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_nll_a = compute_nll(logits_a, target_ids_a)\n",
    "seq_nll_b = compute_nll(logits_b, target_ids_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "765b9513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.7496), tensor(4.3967))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_nll_a, seq_nll_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5649a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maths.softmax import stable_log_softmax, stable_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b2c5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stb_sft = stable_softmax()\n",
    "stb_log_sft = stable_log_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f8e4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(logits: torch.Tensor):\n",
    "    probs = stb_sft(logits, dim=-1)\n",
    "    log_probs = stb_log_sft(logits, dim=-1)\n",
    "    out = - torch.sum(probs * log_probs, dim=-1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e6ae0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.manual_seed(42)\n",
    "logits_a = torch.ones((1, 50))\n",
    "logits_b = torch.ones((1, 50))\n",
    "logits_b[0, 4], logits_b[0, 23] = 100, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee9f5c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
       " tensor([[  1.,   1.,   1.,   1., 100.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "            1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1., 100.,\n",
       "            1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "            1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "            1.,   1.]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_a, logits_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bafa6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_a = compute_entropy(logits_a)\n",
    "out_b = compute_entropy(logits_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d249518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.9120]), tensor([0.6931]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_a, out_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e5f8e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([50.0000]), tensor([2.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(out_a), torch.exp(out_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "525a5ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_values = [0.01, 0.1, 0.2, 0.5, 0.6, 0.8, 1.0, 5.0, 10.0, 25.0, 60.0, 100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd4f4466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6931])\n",
      "tensor([0.6931])\n",
      "tensor([0.6931])\n",
      "tensor([0.6931])\n",
      "tensor([0.6931])\n",
      "tensor([0.6931])\n",
      "tensor([0.6931])\n",
      "tensor([0.6931])\n",
      "tensor([0.7063])\n",
      "tensor([2.3129])\n",
      "tensor([3.7734])\n",
      "tensor([3.8777])\n"
     ]
    }
   ],
   "source": [
    "for t in temp_values:\n",
    "    print(compute_entropy(logits_b/t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "843cddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.9120])\n",
      "tensor([3.9120])\n",
      "tensor([3.9120])\n",
      "tensor([3.9120])\n",
      "tensor([3.9120])\n",
      "tensor([3.9120])\n",
      "tensor([3.9120])\n",
      "tensor([3.9120])\n",
      "tensor([3.9120])\n",
      "tensor([3.9120])\n",
      "tensor([3.9120])\n",
      "tensor([3.9120])\n"
     ]
    }
   ],
   "source": [
    "for t in temp_values:\n",
    "    print(compute_entropy(logits_a/t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd662dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0bb0fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(logits: torch.Tensor, temperature: float=1.0, top_k: int=5, top_p: float= 0.9):\n",
    "    B, C = logits.shape\n",
    "    probs = stb_sft(logits/temperature, dim=-1)\n",
    "    sort_probs, sort_indices = torch.sort(probs, dim=-1, descending=True)\n",
    "    sort_probs = sort_probs[:, :top_k]\n",
    "    sort_indices = sort_indices[:, :top_k]\n",
    "    valid_indices = torch.where(~(torch.cumsum(sort_probs, dim=-1) > top_p), sort_indices, -1)\n",
    "    return valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "02f00e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.manual_seed(42) \n",
    "logits = torch.randn((2, 50), generator=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14e1890b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269e+00,  1.4873e+00,  9.0072e-01, -2.1055e+00,  6.7842e-01,\n",
       "         -1.2345e+00, -4.3067e-02, -1.6047e+00, -7.5214e-01,  1.6487e+00,\n",
       "         -3.9248e-01, -1.4036e+00, -7.2788e-01, -5.5943e-01, -7.6884e-01,\n",
       "          7.6245e-01,  1.6423e+00, -1.5960e-01, -4.9740e-01,  4.3959e-01,\n",
       "         -7.5813e-01,  1.0783e+00,  8.0080e-01,  1.6806e+00,  1.2791e+00,\n",
       "          1.2964e+00,  6.1047e-01,  1.3347e+00, -2.3162e-01,  4.1759e-02,\n",
       "         -2.5158e-01,  8.5986e-01, -1.3847e+00, -8.7124e-01, -2.2337e-01,\n",
       "          1.7174e+00,  3.1888e-01, -4.2452e-01,  3.0572e-01, -7.7459e-01,\n",
       "         -1.5576e+00,  9.9564e-01, -8.7979e-01, -6.0114e-01, -1.2742e+00,\n",
       "          2.1228e+00, -1.2347e+00, -4.8791e-01, -9.1382e-01, -6.5814e-01],\n",
       "        [ 7.8024e-02,  5.2581e-01, -4.8799e-01,  1.1914e+00, -8.1401e-01,\n",
       "         -7.3599e-01, -1.4032e+00,  3.6004e-02, -6.3477e-02,  6.7561e-01,\n",
       "         -9.7807e-02,  1.8446e+00, -1.1845e+00,  1.3835e+00,  1.4451e+00,\n",
       "          8.5641e-01,  2.2181e+00,  5.2317e-01,  3.4665e-01, -1.9733e-01,\n",
       "         -1.0546e+00,  1.2780e+00, -1.7219e-01,  5.2379e-01,  5.6622e-02,\n",
       "          4.2630e-01,  5.7501e-01, -6.4172e-01, -2.2064e+00, -7.5080e-01,\n",
       "          1.0868e-02, -3.3874e-01, -1.3407e+00, -5.8537e-01,  6.4076e-01,\n",
       "          5.8325e-01,  1.0669e+00, -4.5015e-01, -6.7875e-01,  5.7432e-01,\n",
       "          1.8775e-01, -3.5762e-01,  2.6491e-01,  1.2732e+00, -1.3109e-03,\n",
       "         -3.0360e-01, -9.8644e-01,  1.2330e-01,  3.4987e-01,  6.1728e-01]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9b70a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sample(logits, top_p=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8d924f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[45,  0, -1, -1, -1],\n",
       "        [16, 11, -1, -1, -1]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9b9e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maths.softmax import stable_log_softmax, stable_softmax\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b21f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "stb_sft = stable_softmax()\n",
    "stb_log_sft = stable_log_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6fb926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(logits: torch.Tensor):\n",
    "    probs = stb_sft(logits, dim=-1)\n",
    "    log_probs = stb_log_sft(logits, dim=-1)\n",
    "    out = -torch.sum(probs * log_probs, dim=-1)\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0294da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.manual_seed(42)\n",
    "logits_a = torch.ones((1, 50))\n",
    "logits_b = torch.ones((1, 50))\n",
    "logits_b[0, 4] = 100\n",
    "logits_b[0, 25] = 100\n",
    "logits_b[0, 43] = 89\n",
    "logits_c = torch.randn((1, 50), generator=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ddc5593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   1.,   1., 100.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "           1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "           1., 100.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,\n",
       "           1.,   1.,   1.,   1.,   1.,   1.,   1.,  89.,   1.,   1.,   1.,   1.,\n",
       "           1.,   1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44964892",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_a = compute_entropy(logits_a)\n",
    "out_b = compute_entropy(logits_b)\n",
    "out_c = compute_entropy(logits_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7870251f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.9120]), tensor([0.6932]), tensor([3.4912]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_a, out_b, out_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21e0deb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([50.0000]), tensor([2.0002]), tensor([32.8249]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(out_a), torch.exp(out_b), torch.exp(out_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa499d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [0.01, 0.1, 0.2, 0.3, 0.6, 0.9, 1.0, 5.0, 10.0, 15.0, 20.0, 50.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1dbd34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 tensor([0.6931]) tensor([2.])\n",
      "0.1 tensor([0.6931]) tensor([2.])\n",
      "0.2 tensor([0.6931]) tensor([2.])\n",
      "0.3 tensor([0.6931]) tensor([2.])\n",
      "0.6 tensor([0.6931]) tensor([2.0000])\n",
      "0.9 tensor([0.6932]) tensor([2.0001])\n",
      "1.0 tensor([0.6932]) tensor([2.0002])\n",
      "5.0 tensor([0.8626]) tensor([2.3692])\n",
      "10.0 tensor([1.0149]) tensor([2.7591])\n",
      "15.0 tensor([1.2381]) tensor([3.4492])\n",
      "20.0 tensor([1.7435]) tensor([5.7173])\n",
      "50.0 tensor([3.6309]) tensor([37.7482])\n"
     ]
    }
   ],
   "source": [
    "for t in temp:\n",
    "    ent = compute_entropy(logits_b/t)\n",
    "    print(t, ent, torch.exp(ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d66b565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[0.0759, 0.0699, 0.0593, 0.0575, 0.0571]]),\n",
       "indices=tensor([[ 0, 45, 23,  9, 16]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = stb_sft(logits_c, dim=-1)\n",
    "torch.topk(probs, dim=-1, k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c32d3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(logits: torch.Tensor, temperature: float=1.0, top_k: int=10, top_p: float=0.9):\n",
    "    # top-k\n",
    "    logits, logits_indices = torch.topk(logits, k=top_k, dim=-1)\n",
    "    \n",
    "    probs = stb_sft(logits/temperature, dim=-1)\n",
    "    \n",
    "    # top-p\n",
    "    cumsum = torch.cumsum(probs, dim=-1)\n",
    "    mask = cumsum <= top_p\n",
    "    mask[:, 0] = True\n",
    "    mask[:, 1:] |= (cumsum[:, :-1] <= top_p)\n",
    "    probs = torch.where(mask, probs, torch.zeros_like(probs))\n",
    "    probs = probs / torch.sum(probs, dim=-1, keepdim=True)\n",
    "    indices = torch.multinomial(probs, num_samples=1)\n",
    "    return torch.gather(logits_indices, dim=-1, index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "318d9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(logits: torch.Tensor, temperature: float=1.0, top_k: int=10, top_p: float=0.9):\n",
    "    probs = stb_sft(logits/temperature, dim=-1)\n",
    "    # top-k\n",
    "    probs, prob_indices = torch.topk(probs, k=top_k, dim=-1)\n",
    "    \n",
    "    # top-p\n",
    "    cumsum = torch.cumsum(probs, dim=-1)\n",
    "    mask = cumsum <= top_p\n",
    "    mask[:, 0] = True\n",
    "    mask[:, 1:] |= (cumsum[:, :-1] <= top_p)\n",
    "    probs = torch.where(mask, probs, torch.zeros_like(probs))\n",
    "    probs = probs / torch.sum(probs, dim=-1, keepdim=True)\n",
    "    indices = torch.multinomial(probs, num_samples=1)\n",
    "    print(prob_indices.shape, indices.shape)\n",
    "    return torch.gather(prob_indices, dim=-1, index=indices)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2335211",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.manual_seed(42)\n",
    "logits = torch.randn((2, 50), generator=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76e5a320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5]) torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0],\n",
       "        [14]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(logits, top_p=0.2, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8086ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nll(logits: torch.Tensor, target_ids: torch.Tensor):\n",
    "    B, T, C = logits.shape\n",
    "    B_t, T_t = target_ids.shape\n",
    "    assert B==B_t and T == T_t\n",
    "    log_probs = stb_log_sft(logits, dim=-1)\n",
    "    log_probs = torch.gather(log_probs, dim=-1, index=target_ids.unsqueeze(-1)).squeeze(-1)\n",
    "    out = - torch.sum(log_probs)/(T*B)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f984e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.manual_seed(42)\n",
    "logits = torch.randn((2, 10, 50), generator=gen)\n",
    "target_ids = torch.randint(0, 50, (2, 10), generator=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a6ce6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.4533), tensor(3.4519))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = compute_nll(logits, target_ids)\n",
    "out_e = compute_entropy(logits)\n",
    "out_e = torch.sum(out_e)/out_e.numel()\n",
    "out, out_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fbb24191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(85.9116), tensor(31.5609))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(out), torch.exp(out_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "93704944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1]) torch.Size([2, 1, 50]) torch.Size([2, 1, 50])\n"
     ]
    }
   ],
   "source": [
    "gen = torch.manual_seed(42)\n",
    "cheating = torch.randn((2, 1, 50), generator=gen)\n",
    "cheating[0, 0, 10] = 25\n",
    "cheating[1, 0, 21] = 100\n",
    "target_ids = torch.tensor([[10], [21]])\n",
    "clueless = torch.ones((2, 1, 50))\n",
    "print(target_ids.shape, cheating.shape, clueless.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20988b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.), tensor(3.9120))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_cheating = compute_nll(cheating, target_ids)\n",
    "out_clueless = compute_nll(clueless, target_ids)\n",
    "out_cheating, out_clueless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6708f172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(50.0000))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(out_cheating), torch.exp(out_clueless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maths.softmax import stable_softmax\n",
    "from config import device\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fb9ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, dim: int, seq_len: int, num_head:int, head_dim: int, is_causal: bool=True):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.seq_len = seq_len\n",
    "        self.num_head = num_head\n",
    "        self.head_dim = head_dim\n",
    "        self.is_causal = is_causal\n",
    "        self.q_w = nn.Linear(self.dim, self.num_head * self.head_dim)\n",
    "        self.k_w = nn.Linear(self.dim, self.num_head * self.head_dim)\n",
    "        self.v_w = nn.Linear(self.dim, self.num_head * self.head_dim)\n",
    "\n",
    "        self.w_o = nn.Linear(self.num_head * self.head_dim, self.dim)\n",
    "        self.stb_sft = stable_softmax()\n",
    "        self.register_buffer('tril', torch.tril(torch.ones((seq_len, seq_len)).bool()).unsqueeze(0).unsqueeze(1))\n",
    "    \n",
    "    def forward(self, x, mask = None):\n",
    "        B, T, C = x.shape\n",
    "        q = self.q_w(x)\n",
    "        k = self.k_w(x)\n",
    "        v = self.v_w(x)\n",
    "\n",
    "        q = q.contiguous().view(B, T, self.num_head, self.head_dim).transpose(1, 2)\n",
    "        k = k.contiguous().view(B, T, self.num_head, self.head_dim).transpose(1, 2)\n",
    "        v = v.contiguous().view(B, T, self.num_head, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * (self.head_dim ** -0.5)\n",
    "        if self.is_causal:\n",
    "            attn = attn.masked_fill(~self.tril[:, :, :T, :T], value=float('-inf'))\n",
    "        \n",
    "        if mask is not None:\n",
    "            if mask.dim()==2:\n",
    "                mask = mask.unsqueeze(1).unsqueeze(1)\n",
    "            attn = attn.masked_fill(~mask, value=float('-inf'))\n",
    "        \n",
    "        attn_scores = self.stb_sft(attn, dim=-1)\n",
    "\n",
    "        out = attn_scores @ v\n",
    "        out = out.transpose(1, 2).reshape(B, T, self.num_head*self.head_dim)\n",
    "        out = self.w_o(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "737279c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10\n",
    "T = 256\n",
    "C = 512\n",
    "num_head = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a392942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attns_module = SelfAttention(dim=C, seq_len=T, num_head=num_head, head_dim=C//num_head).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8849d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.Generator(device=device)\n",
    "gen.manual_seed(42)\n",
    "\n",
    "x = torch.randn((B, T, C), generator=gen, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db9dd807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 512])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdba06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = attns_module(x, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4334b4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "617cd627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.0777e-01, -2.8475e-01,  7.4862e-01, -1.8293e-01, -7.9914e-02,\n",
       "        -4.7595e-02, -2.8990e-01,  7.4373e-02, -4.9075e-01,  6.1789e-01,\n",
       "        -2.2332e-01,  3.9436e-01, -6.9272e-02, -1.1194e-01,  6.1884e-01,\n",
       "        -4.0441e-01, -2.2336e-01, -2.0348e-01,  4.7485e-01,  1.1459e-01,\n",
       "        -6.9173e-03, -1.3378e-01,  2.6216e-02, -4.1331e-01, -1.7349e-01,\n",
       "         1.1603e-01, -4.9984e-01, -5.8381e-01,  7.0129e-02,  1.5205e-01,\n",
       "        -8.9764e-02, -5.0892e-01,  5.5400e-01,  1.3133e-01, -5.0637e-03,\n",
       "        -1.3070e-01, -2.9773e-01, -5.7534e-01,  4.4412e-01, -1.9810e-01,\n",
       "        -3.9218e-02,  3.3281e-01,  2.7967e-02,  2.5573e-03, -1.5771e-01,\n",
       "        -3.0615e-01,  8.6153e-02,  2.7363e-01,  6.2711e-01,  2.7965e-01,\n",
       "         7.8249e-01,  2.4900e-01,  1.0584e-01,  4.2118e-01,  2.2307e-01,\n",
       "         9.3330e-02,  7.1194e-01,  9.8989e-02, -2.0547e-01,  3.9773e-01,\n",
       "         3.4572e-01,  3.6400e-01, -1.1486e-01,  2.2085e-01, -1.9148e-01,\n",
       "        -1.1554e-01,  3.0440e-01, -2.8248e-01, -1.3328e-01, -1.7172e-01,\n",
       "        -2.7597e-01,  4.4588e-01,  2.2235e-01,  9.3512e-02,  6.6696e-02,\n",
       "        -4.2903e-01, -3.4914e-01, -2.8109e-01, -4.2668e-01,  2.6905e-01,\n",
       "         7.1021e-02,  1.5330e-02, -3.2195e-01, -4.8341e-01, -2.7467e-02,\n",
       "        -3.3188e-01,  9.4504e-02, -3.0312e-01, -5.7639e-01, -4.0757e-01,\n",
       "         5.6724e-01,  2.4792e-01, -6.3818e-01, -2.8294e-01, -5.7374e-01,\n",
       "         7.0038e-02,  1.9805e-01,  1.0539e-01, -6.8497e-01,  2.3512e-01,\n",
       "         2.7674e-02,  5.9305e-02, -2.8637e-02,  1.3869e-01,  2.6564e-02,\n",
       "        -2.3417e-01,  5.4025e-03,  6.0591e-02, -4.0385e-01, -7.5685e-01,\n",
       "        -4.7560e-01,  1.5175e-01, -2.7494e-01,  1.2014e-02,  6.0953e-01,\n",
       "        -8.9145e-01,  1.3146e-01, -2.5293e-01, -4.9765e-01,  6.8154e-03,\n",
       "        -3.6574e-01, -9.5161e-02,  7.1063e-01,  4.2210e-01,  4.5504e-01,\n",
       "         2.3825e-01,  1.1105e-01,  4.6115e-01, -4.2775e-01,  2.7166e-01,\n",
       "        -2.2119e-01,  1.3694e-01,  2.0604e-01, -1.3771e-01, -6.0126e-03,\n",
       "         3.2935e-01, -1.7077e-01,  5.2176e-01,  4.1853e-02, -5.1451e-01,\n",
       "        -1.4494e-01,  7.8484e-02,  4.8904e-01,  5.5033e-01,  8.1326e-02,\n",
       "        -1.3911e-01,  5.0356e-01, -1.9357e-01, -3.7699e-01,  1.1158e-01,\n",
       "         1.7013e-01,  1.8909e-01,  1.7526e-01,  4.0484e-01, -6.1594e-02,\n",
       "         2.2744e-01, -2.5934e-01,  3.9846e-01, -3.5185e-01,  7.6653e-01,\n",
       "        -1.5216e-01, -5.4548e-02, -4.2624e-01,  1.6704e-01,  5.4098e-01,\n",
       "         5.3561e-02, -1.8968e-01, -5.0330e-01,  1.6397e-01, -2.6111e-01,\n",
       "        -3.1210e-01, -3.0514e-01, -7.1773e-02, -3.4256e-01,  1.4088e-02,\n",
       "        -1.1625e-01, -2.1181e-01, -1.8796e-01, -3.9882e-01,  4.9815e-01,\n",
       "        -2.9999e-02, -2.0416e-01, -5.0477e-02, -6.3424e-01,  6.7542e-01,\n",
       "        -6.0199e-01,  1.3507e-01,  1.9544e-01, -2.3210e-01,  4.7018e-01,\n",
       "        -1.3511e-02,  1.0813e-01,  6.2728e-01, -1.3502e-01, -1.0172e-01,\n",
       "         4.6164e-01,  3.1040e-01,  3.2928e-01,  5.8272e-01,  3.8983e-01,\n",
       "         3.0679e-01,  5.0662e-01,  3.5129e-02, -4.6163e-01,  8.0991e-02,\n",
       "        -4.4785e-02,  2.8597e-01,  7.5574e-02, -1.1644e-01, -1.1073e-01,\n",
       "        -4.9768e-03, -6.3890e-02,  1.3246e-01,  2.3350e-01, -5.1319e-01,\n",
       "        -7.3955e-02,  1.5254e-01,  2.7211e-01, -1.1830e-01,  1.9732e-01,\n",
       "         4.0212e-01, -1.5964e-01, -4.7764e-01,  5.3906e-01, -1.1504e-01,\n",
       "         7.6416e-01, -7.2380e-01, -1.4195e-01,  5.9151e-02,  1.7505e-01,\n",
       "        -1.5869e-01,  6.8043e-02,  3.0129e-01,  3.8368e-01, -1.5792e-01,\n",
       "        -1.5442e-01, -1.3913e-01, -1.4505e-01, -2.7959e-01, -1.7228e-01,\n",
       "        -2.0567e-01,  3.2174e-01, -4.4532e-01, -8.2157e-01,  2.0838e-02,\n",
       "        -1.0555e+00, -2.0244e-01,  2.6928e-01, -2.7961e-02,  2.0900e-01,\n",
       "        -1.3155e-02,  3.3702e-01, -5.3475e-01,  3.1334e-01, -6.5520e-02,\n",
       "         2.0733e-01,  4.1191e-01,  9.5986e-02,  1.9460e-01,  2.7542e-01,\n",
       "         3.7365e-01, -2.3521e-01, -1.8860e-01, -2.4447e-01, -1.5420e-01,\n",
       "         8.9424e-01, -3.5599e-01, -5.4981e-01,  1.0408e-01, -2.3560e-01,\n",
       "        -5.3067e-03,  1.9752e-01, -2.3210e-01,  6.0563e-01, -4.9180e-01,\n",
       "        -8.9227e-02, -8.2035e-02, -4.1328e-01,  1.8043e-01, -2.4784e-01,\n",
       "         3.1600e-01,  1.4805e-02,  2.2699e-01,  1.9160e-01,  1.3155e-01,\n",
       "         4.7027e-02,  5.0929e-01,  4.5460e-02, -2.1325e-02, -2.8140e-01,\n",
       "         2.9771e-01, -3.5281e-01, -1.1337e-01,  9.9477e-02,  3.2966e-01,\n",
       "         4.3366e-01,  1.4954e-01,  3.1558e-01,  1.1508e-01,  1.1736e-01,\n",
       "         1.2323e-01, -2.0342e-01,  5.2036e-02,  2.4042e-01, -1.0360e-01,\n",
       "        -5.0595e-01, -6.0052e-01, -2.6939e-02,  1.4610e-01,  1.4848e-01,\n",
       "         5.3661e-01, -1.5430e-01,  2.3699e-01,  1.4340e-01, -1.0500e-01,\n",
       "         3.1854e-01,  1.0024e-01, -2.6347e-01,  4.9019e-01, -3.7523e-01,\n",
       "        -1.7950e-01,  1.0125e-01,  1.1803e-01, -3.1410e-01, -2.2663e-01,\n",
       "        -2.9092e-01, -3.0172e-01,  5.0362e-01,  3.1549e-01, -4.8369e-01,\n",
       "         4.8043e-01,  4.9384e-01, -1.3872e-01,  5.8069e-01, -1.0925e-01,\n",
       "         3.7213e-01,  3.4892e-01,  3.2296e-01, -3.5691e-01,  5.5803e-02,\n",
       "         2.5429e-01, -1.1937e-01,  5.6411e-02, -2.3111e-01, -3.8825e-01,\n",
       "         2.6344e-02,  1.7255e-01,  2.2594e-02, -1.3856e-01, -3.3596e-02,\n",
       "        -2.2415e-01, -1.2599e-01, -3.0522e-01,  7.1611e-02,  1.0577e-01,\n",
       "        -7.9926e-01, -2.9148e-01,  2.6889e-01,  8.4223e-02,  5.3806e-01,\n",
       "         5.4073e-01,  7.7295e-01, -4.5054e-01, -2.0445e-01, -1.9581e-01,\n",
       "        -2.1082e-01,  2.2683e-01,  1.5868e-01,  1.9235e-01, -6.7591e-02,\n",
       "        -4.2731e-01, -6.7392e-02, -2.3735e-02,  4.1088e-02, -7.0591e-01,\n",
       "         1.4974e-02, -6.1613e-01, -1.9290e-01,  1.5141e-01, -4.7507e-01,\n",
       "        -6.1138e-01,  9.7779e-02,  2.3988e-01,  5.4057e-01,  1.1717e-01,\n",
       "        -2.5032e-01, -4.8514e-01,  2.0975e-01, -3.9343e-01,  1.3643e-01,\n",
       "         1.5866e-01,  3.4498e-01, -1.9461e-01,  3.5739e-01, -3.5528e-01,\n",
       "         2.3809e-01, -3.5714e-01, -2.2473e-01,  4.6150e-03, -6.4463e-01,\n",
       "         5.6110e-02, -1.0942e-01,  6.6265e-02, -3.5439e-01,  9.2393e-02,\n",
       "        -9.6102e-02,  3.5576e-01, -1.2153e-01,  5.1092e-01,  3.5542e-01,\n",
       "         6.0888e-02, -6.5467e-01, -2.7089e-01,  6.0537e-01, -4.8623e-01,\n",
       "         3.7824e-01,  6.4166e-01, -3.1308e-02, -3.3927e-01, -4.3130e-01,\n",
       "        -5.4645e-03, -3.3367e-01,  2.6911e-01, -2.3565e-01, -6.4431e-02,\n",
       "        -7.2480e-02,  1.4630e-01,  1.5444e-01,  2.8097e-02,  5.4080e-01,\n",
       "        -5.1109e-01, -2.1601e-02,  1.5244e-01, -2.6314e-02,  2.6136e-01,\n",
       "         4.7692e-01,  1.2194e-01, -4.2538e-02,  1.1723e-01,  8.8527e-02,\n",
       "         1.8544e-01, -2.1524e-01,  1.1727e-01,  2.7303e-01,  3.8307e-01,\n",
       "        -1.8835e-01,  3.6546e-01,  1.0398e-01,  3.9961e-01, -4.3841e-01,\n",
       "        -6.0122e-01,  1.7999e-02,  3.3407e-01,  3.9930e-01, -1.8000e-01,\n",
       "        -4.6813e-03, -4.9875e-01, -1.6568e-01, -4.9589e-01, -6.9634e-02,\n",
       "         3.6215e-01, -5.3768e-01,  1.5021e-01,  5.1503e-01,  1.1711e-01,\n",
       "        -3.0343e-02, -2.9277e-02,  6.2294e-02,  3.6054e-01,  4.3408e-01,\n",
       "        -2.2040e-01,  1.7389e-01,  5.4651e-01,  2.4642e-01, -1.0551e+00,\n",
       "         1.5439e-01, -4.3117e-01,  2.2393e-01, -2.2949e-02,  6.9692e-01,\n",
       "        -4.4163e-01,  7.7113e-01, -9.7778e-02,  5.0123e-01,  2.3346e-01,\n",
       "        -9.4323e-04, -2.5600e-01,  4.4072e-01, -2.6475e-01, -2.4391e-01,\n",
       "        -3.6575e-01, -2.7658e-01, -2.0495e-01, -1.0956e-01, -1.0731e-01,\n",
       "        -3.1346e-01,  1.0779e-05,  1.2078e-01,  3.0738e-01, -1.0750e-03,\n",
       "        -7.9418e-03,  5.0994e-03, -6.3311e-02, -5.4359e-01,  2.6694e-02,\n",
       "         2.3779e-01, -2.2303e-01, -4.4374e-02, -2.4914e-01, -5.6902e-02,\n",
       "         1.1666e-01, -1.2494e-01], device='mps:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26a078a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjLayer(nn.Module):\n",
    "    def __init__(self, dim: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.proj = nn.Linear(self.dim, self.vocab_size)\n",
    "        self.stb_sft = stable_softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        out = self.proj(x)\n",
    "        out = self.stb_sft(out, dim=-1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "feaeb8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 256, 512]), 512)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f42649d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_layer = ProjLayer(dim=C, vocab_size=1000).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4c70c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_out = proj_layer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25e406f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 1000])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b54498ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, vocab_size: int, dim: int):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embddings = nn.Embedding(self.vocab_size, self.dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embddings(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4492955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10\n",
    "T = 256\n",
    "C = 512\n",
    "VOCAB_SIZE = 1000\n",
    "num_head = 4\n",
    "head_dim = C//num_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1da8603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = EmbeddingLayer(VOCAB_SIZE, C).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21477771",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.Generator(device)\n",
    "gen.manual_seed(42)\n",
    "x = torch.randint(0, VOCAB_SIZE, (B, T), device=device, generator=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d1066af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3764427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embedding_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db8e6a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 512])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3fcbb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "attns_module = SelfAttention(dim=C, seq_len=T, num_head=num_head, head_dim=head_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60377f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = attns_module(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8df4a621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "56b2182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_layer = ProjLayer(dim=C, vocab_size=VOCAB_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df25c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_out = proj_layer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31038c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 1000])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f61a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
